{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Transforming Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've learned how to make visualizations and compute some simple statistics to describe our data. As we continue along in this course, we'll want to find more ways to make comparisons between various datasets, some of which might involve different measurement scales. We might need to scale our data, or use some sort of transformation, which is what we'll be discussing in this video. Along the way, I'll talk about how transformations can help us deal with data that aren't normally distributed, the effect of these transformations on visualizations, and how they can both help, or hinder, how we make sense of a particular problem. So, with that said, let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apples to Oranges: Comparing Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Say we're trying to compare how students perform on college entrance exams at two different fictional high \n",
    "#schools in the US. One is in California (Sunnydale High), where a large majority tend to take the SAT, and \n",
    "#the other is in Illinois (Shermer High), where students favor the ACT. Is there anyway for us to tell how\n",
    "#these schools stack up to one another?\n",
    "\n",
    "#So below, we've collected a sample of scores from Sunnydale High vs. Shermer High.\n",
    "#As you may be able to roughly tell, the SAT scores range from 300-800 points...\n",
    "SAT_scores = [690, 330, 600, 350, 540, 440, 650, 480, 570, 420, 360, 620, 580, 600,\n",
    " 390, 420, 510, 640, 350, 470, 570, 430, 410, 420, 380, 420, 510, 620,\n",
    " 470, 700, 520, 560, 480, 540, 450, 550, 520, 460, 410, 550, 400, 350,\n",
    " 780, 590, 510, 410, 520, 340, 430, 370, 560, 560, 500, 560, 490, 550,\n",
    " 430, 520, 710, 520, 460, 390, 550, 410, 480, 450, 520, 610, 380, 620,\n",
    " 530, 460, 460, 660, 520, 580, 490, 560, 520, 380, 440, 610, 530, 350,\n",
    " 630, 440, 450, 590, 430, 640, 500, 290, 560, 390, 320, 470, 700, 540,\n",
    " 440, 550]\n",
    "\n",
    "#...while the ACT scores range from 1 to 36.\n",
    "ACT_scores = [24, 18, 32, 23, 22, 26, 18, 23, 17, 28, 15, 20, 20, 17, 19, 24, 17, 29,\n",
    " 21, 31, 22, 13, 17, 17, 26, 16, 25, 30, 26, 14, 14, 22, 14, 29, 26, 27,\n",
    " 25, 20, 19, 17, 31, 20, 20, 25, 19, 24, 23, 24, 24, 23, 17, 18, 21, 26,\n",
    " 21, 21, 28, 22, 22, 21, 18, 10, 16, 25, 31, 23, 24, 18, 28, 18, 20, 23,\n",
    " 22, 17, 16, 17, 29, 25, 18, 19, 20, 22, 29, 18, 17, 24, 15, 33, 30, 17,\n",
    " 11, 25, 24, 20, 21, 21, 29, 25, 22, 18]\n",
    "\n",
    "#Let's go ahead and store these values as a Pandas Dataframe.\n",
    "columns = [\"SAT\", \"ACT\"]\n",
    "score_df = #YOUR CODE HERE\n",
    "print(score_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a transformation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a reasonable comparison, we're going to need to transform the data in some way. Specifically, when \n",
    "I talk about a transformation, all that means is that we're going to apply some function, $f(x)$, to each input, \n",
    "and get our new outputs. So, something as simple as $x + 0$ counts as a (trivial) transformation, as does a much more \n",
    "complicated expression, such as the one below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\hat{f}(k) = \\int_{-\\infty}^{\\infty}f(x) e^{-2\\pi i kx} dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, adding zero isn't a particularly *useful* transformation. And as for the second one, it's certainly \n",
    "useful, but not something you'll have to worry about in this course (if you're curious, it's actually a Fourier Transform, which has many applications relating to time series data that we won't dive deep into here). I'll be sure to point out the \n",
    "essential transformations you're going to run across when reading other peoples' analyses, and provide you\n",
    "with all the tools necessary to get started on your own. Now, relating transformations back to our original \n",
    "question regarding test scores..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling Techniques\n",
    "\n",
    "Max-Min Normalization\n",
    "\n",
    "$$ x' = \\frac{x-\\min(x)}{\\max(x)-\\min(x)} $$\n",
    "\n",
    "Standardization (z-score)\n",
    "\n",
    "$$ x' = \\frac{x - \\mu}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that the difficulty comes from having two different measures. Scaling allows us to use the same \n",
    "#measuring stick and start to draw some conclusions based on the data. One way of scaling the data is to use \n",
    "#max-min normalization, which transforms all our values between 0 and 1. However, in our particular case, it\n",
    "#might be more helpful to look at standardization, or in other words, compute z-scores. Recall that this \n",
    "#just captures the difference between your data point and the mean, relative to the spread of the overall \n",
    "#distribution.\n",
    "\n",
    "#Now let's go ahead and pause for a quick refresher. Try your hand at calculating a z-scores.\n",
    "#QUIZ: Hand-compute max-min/z-score (x=0 and Dataset: 1 2 2 2 3 3 4 5 5)\n",
    "\n",
    "#Instead of using the raw scores, we've used the z-scores to compute mu and sigma, and then looked up \n",
    "#the national averages and standard deviations for both exams so that we can benchmark each school \n",
    "#relative to how the rest of the country performed. \n",
    "\n",
    "#2017 data obtained from https://nces.ed.gov/programs/digest/current_tables.asp (Tables 226.XX)\n",
    "SAT_mean = 527\n",
    "SAT_sd = 107\n",
    "\n",
    "ACT_mean = 20.7\n",
    "ACT_sd = 5.5\n",
    "\n",
    "#with that info, we can then calculate a normalized dataframe and store this into normalized_df\n",
    "SAT_norm = #YOUR CODE HERE\n",
    "ACT_norm = #YOUR CODE HERE\n",
    "normalized_df = #YOUR CODE HERE\n",
    "\n",
    "#Let's go ahead and plot the normalized SAT scores from Sunnydale and see what happens.\n",
    "plt.hist(normalized_df['SAT'], bins=12)\n",
    "\n",
    "#Even though we haven't discussed histograms yet, we can still get a vague sense of what's going on here. \n",
    "#Specifically, note that it kind of resembles a normal distribution: \n",
    "#there's a hump--somewhat left of center--that tails off on both ends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we'll repeat the same thing for the normalized ACT scores from Shermer High.\n",
    "plt.hist(normalized_df['ACT'], bins=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's print out some centrality measures. \n",
    "#Print out the mean and median SAT and ACT scores for each school.\n",
    "\n",
    "\n",
    "\n",
    "#What do you notice? Does this match the visuals?\n",
    "#Admittedly, this isn't very rigorous, but it does show how a simple transformation combined \n",
    "#with some basic visual exploration is an effective way of getting some quick insights from your data. \n",
    "#We can also take a look at some procedures to more confidently answer similar questions\n",
    "#using grounded statistical techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Study: New York Stock Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll end this lecture by going through a case study. The following data are the closing values for the Dow\n",
    "#Jones Industrial Average (DJIA), a stock market index of 30 large, publicly owned companies based in the US\n",
    "#from 1915 to 2018. Note that the most recent global 2008 recession is clearly depicted. Can you identify any \n",
    "#other recessions? How we would identify periods of economic downturn or stagnation in general?\n",
    "\n",
    "#Data obtained from https://www.macrotrends.net/1319/dow-jones-100-year-historical-chart \n",
    "years = np.arange(1915, 2019, 1) \n",
    "closing_values = [99.15, 95.00, 74.38, 82.20, 107.23, 71.95, 80.80, 98.17, 95.52, 120.51, 151.08, 157.20, 200.70, 300.00, \n",
    "                  248.48, 164.58, 77.90, 59.93, 99.90, 104.04, 144.13, 179.90, 120.85, 154.76, 150.24, 131.13, 110.96, 119.40, \n",
    "                  135.89, 152.32, 192.91, 177.20, 181.16, 177.30, 200.13, 235.41, 269.23, 291.90, 280.90, 404.39, 488.40, \n",
    "                  499.47, 435.69, 583.65, 679.36, 615.89, 731.14, 652.10, 762.95, 874.13, 969.26, 785.69, 905.11, 943.75, \n",
    "                  800.36, 838.92, 890.20, 1020.02, 850.86, 616.24, 852.41, 1004.65, 831.17, 805.01, 838.74, 963.99, 875.00, \n",
    "                  1046.54, 1258.64, 1211.57, 1546.67, 1895.95, 1938.83, 2168.57, 2753.20, 2633.66, 3168.83, 3301.11, 3754.09, \n",
    "                  3834.44, 5117.12, 6448.27, 7908.30, 9181.43, 11497.12, 10787.99, 10021.57, 8341.63, 10453.92, 10783.01, \n",
    "                  10717.50, 12463.15, 13264.82, 8776.39, 10428.05, 11577.51, 12217.56, 13104.14, 16576.66, 17823.07, 17425.03, \n",
    "                  19762.60, 24719.22, 23327.46]\n",
    "\n",
    "plt.plot(years, closing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          Crowds outside NYSE after crash       | \"Bank runs\"       |\n",
    "|:-----------------:| :------------------------: |\n",
    "|  ![Crowds outside NYSE](Crowd_NYSE.jpg)        | ![American Union Bank](American_Union_Bank.png)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For those of you who are familiar with US history, you may know that there was a severe worldwide economic \n",
    "#downturn in the 1930s, after WWI and before the start of WWII. The unemployment rate reached 25%, banks \n",
    "#began to fail, and a swaths of people lined up to withdraw whatever savings they had left, as depicted\n",
    "#above. The \"Great Depression\",doesn't seem to appear in our plot though. Why is that?\n",
    "\n",
    "#Why might the Great Depression not show up in our graph? Try and fix this issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voila! Now the Great Depression is clearly visible. Even though a change of 30 points may seem minisciule \n",
    "#nowadays, on October 29, 1929, or \"Black Tuesday\", this was a 12% decrease, which accounts for a significant \n",
    "#portion of that giant dropoff in the left-hand side of the graph. Note that there are a few other periods \n",
    "#where the market seems to stagnate, and while it's still difficult to precisely pinpoint every major \n",
    "#recession, we are able to make out a lot more intricacies of the data, whereas this was all shrouded before\n",
    "#we applied the transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which transformation should I choose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Not a \"one size fits all\" process, should start by exploring your data \n",
    "- Normalizing data is a common and sometimes necessary transformation for applying later steps in a statistical pipeline\n",
    "- Reciprocal and logarithmic transformation are other useful transformations to know\n",
    "- These transformations have visual effects: the right choice might make analysis easier or emphasize different features of the data\n",
    "- Very useful resource for much of the information in this lecture http://fmwww.bc.edu/repec/bocode/t/transint.html\n",
    "- In the next section, we'll look at some ways to spruce up our graphs (previewed here), such as drawing trendlines, highlighting regions, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
