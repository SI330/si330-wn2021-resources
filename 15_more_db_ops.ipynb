{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgres://jovyan:si330studentuser@localhost:5432/si330"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced Operations!\n",
    "\n",
    "* To get data out of the database and work with it we use the SELECT statement\n",
    "* The select statement requires us at a minimum to indicate the columns we are interested in and the table we are interested in\n",
    "* Base form is `SELECT cols FROM table`\n",
    "* Note that the return value of the select statement is itself a relation (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql postgres://jovyan:si330studentuser@localhost:5432/si330\n",
    "import psycopg2\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "engine = sqlalchemy.create_engine('postgres://jovyan:si330studentuser@localhost:5432/si330')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select first_name from person;\n",
    "# we can limit this to a certain number of rows with the LIMIT clause\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Statements in SQL are terminated with a semicolon, but when we are executing them in python the library which handles the connection will generally terminate the statement for us at the end of the line\n",
    "* Notice that the return relation isn't sorted. It's up to the database to determine what order the items you get are in\n",
    "* Beyond this, the database can choose any ten items when you make a limit call; there is no intrinsic ordering of your results, though some database vendors may choose to do so based on recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when you select multiple columns from a single database the results are row consistent, \n",
    "# e.g. the first name and last names align\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's common to use an * as a wildcard for any column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can limit the results we want to return using a WHERE clouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the single quotes for strings in sql!\n",
    "# there are two wildcard options with varchar matching in SQL:\n",
    "# _ matches a single character\n",
    "# % matches any number of characters\n",
    "# to use these we must use the LIKE operator\n",
    "\n",
    "# find all people who have a name which starts with Chris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unfortunatly, this form of string comparison is super limited. But it's pretty easy to optimize, so you should be aware of how to use it\n",
    "* SQL has no regex functionality built into it :(\n",
    "* (But the dirty truth is everyone loves regex so much you can use regex with a few custom functions)\n",
    "* String matching is of course, case sensitive\n",
    "* We can negate the like operator too with NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numeric columns we can also use our regular numeric operators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL uses an odd syntax for not equals, the <> operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can chain multiple where comparisons together using AND\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how would you have written the above in pandas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another nice function in sql for ranges is BETWEEN and NOT BETWEEN (which are inclusive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another important operator is IN, which does set comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation and Subselects\n",
    "In SQL, we can use aggregation functions as well.\n",
    "\n",
    "An aggregation converts a vector into a scalar, just like in Pandas. Lots of values in, one value out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use these on the columns\n",
    "# How many first_name rows are there in the table person?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's more common to see people count all of the columns, functionally there is a difference but the pattern is so common\n",
    "# databases return the result quickly. Of course, the length (count) of each column is the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lots of other aggregation functions exist as you might expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an interesting query, because the return table has one row, three columns, and is just a bunch of\n",
    "# summary information. Remember, the return value of a select statement is always itself a table (relation)\n",
    "# How might we try and get a list of all unique firstnames with a count of how many occur \n",
    "# in our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select count(first_name), first_name from person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This doesn't do what we want. Just like in pandas we need to tell SQL how we want to \n",
    "# group the data. once we group the data then the return result is just a combination \n",
    "# of the aggregation functions (note alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql \n",
    "select first_name as firstname_nounderscore, count(first_name) as awesome_column\n",
    "from person \n",
    "group by first_name \n",
    "order by first_name\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just like in pandas we can group by multiple columns. This means we need a unique \n",
    "# combination of the two columns\n",
    "# remember that cell magics (%%) must start the cell, can't have comments up top!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "select first_name, last_name, count(*) as num\n",
    "from person\n",
    "where first_name like 'Chris%'\n",
    "group by first_name, last_name\n",
    "order by num desc\n",
    "limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, you've heard me say again and again that every select returns a table, and we \n",
    "# know that select statements work on tables, so why not have a select statement work on \n",
    "# a select statement result?\n",
    "\n",
    "# These are called subselects, and it's a beautiful beautiful thing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "* How do we get data into a database?\n",
    "* There are several different patterns, and at a high level you will hear this refered to as an ETL process: extract, transform, load\n",
    "* This is often used in data warehousing specifically, and is usually done as a batch process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Steps\n",
    "* The first step is extraction, where we pull data out of various databases. This could be csv, json files, or other SQL databases\n",
    "* The second step is to transform it. Sometimes this is aligning data structures, mapping columns, or reducing the data.\n",
    "* The third part is to load it, to push it into a new data warehouse (or database) as a solution\n",
    "* Overall we call the ETL process a \"pipeline\" (or pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://webassets.mongodb.com/_com_assets/cms/ETL_Visual-sa656kl6df.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Thoughts\n",
    "* ETL is useful in reducing dependancies in the data created for warehouses and data marts\n",
    "* ETL process can help with permissions issues and heterogeoneity of data sources, especially in an increasingly json world\n",
    "* ETL tools are robust and processes are well known\n",
    "* At the same time, the ETL process overall can be fragile depending upon the developer building it (all it takes is one failed statement to stop a pipeline)\n",
    "* ETL is slow, and the batch-nature means that the data you are looking at is often not live"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
